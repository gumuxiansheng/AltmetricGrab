{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab Altmetric.com Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Request Functions\n",
    "This part contains functions we need to fetch the web data and should also handle the exceptions while fetching here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grab_util import *\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import threading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_folder = 'SUSTC_Journals/articles_all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grab altmetric.com Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_altmetric_id(doi):\n",
    "    detail_id = ''\n",
    "    res = grab_from_url_json('https://api.altmetric.com/v1/doi/' + doi)\n",
    "    if res is not None:\n",
    "        detail_id = res['altmetric_id']\n",
    "    return detail_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles_df = pd.read_csv(f'{origin_folder}/all.csv', usecols=['SO', 'DI'])\n",
    "df = pd.DataFrame(columns=['DI', 'altmetric_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_altmetric_ids(start_index, end_index):\n",
    "    dfy =pd.DataFrame()\n",
    "\n",
    "    all_articles_df_slice = all_articles_df[start_index:end_index]\n",
    "    for index, doi in enumerate(all_articles_df_slice['DI']):\n",
    "        if doi in df['DI'].values:\n",
    "            continue\n",
    "        if index % 500 == 0:\n",
    "             print(index)\n",
    "        dfx = pd.DataFrame(columns=['DI', 'altmetric_id'])\n",
    "        dfx['DI'] = [doi]\n",
    "        dfx['altmetric_id'] = [get_altmetric_id(str(doi))]\n",
    "        dfy = dfy.append(dfx, ignore_index=True)\n",
    "    return dfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class grabIdThread(threading.Thread):\n",
    "    def __init__(self, threadID, name, start_index, end_index):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.threadID = threadID\n",
    "        self.name = name\n",
    "        self.start_index = start_index\n",
    "        self.end_index = end_index\n",
    "    def run(self):\n",
    "        global df\n",
    "        dfy = grab_altmetric_ids(self.start_index, self.end_index)\n",
    "        threadLock.acquire()\n",
    "        df = df.append(dfy)\n",
    "        threadLock.release()\n",
    "\n",
    "threadLock = threading.Lock()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<grabIdThread(thread_0_1000, initial)>\n0<grabIdThread(thread_1000_2000, initial)>\n\n0<grabIdThread(thread_2000_3000, initial)>\n\n0<grabIdThread(thread_3000_4000, initial)>\n0\n<grabIdThread(thread_4000_5000, initial)>\n0\n\n<grabIdThread(thread_5000_6000, initial)>\n0<grabIdThread(thread_6000_7000, initial)>\n\n0<grabIdThread(thread_7000_8000, initial)>\n0<grabIdThread(thread_8000_9000, initial)>\n\n\n0<grabIdThread(thread_9000_10000, initial)>\n\n0<grabIdThread(thread_10000_11000, initial)>\n\n0<grabIdThread(thread_11000_12000, initial)>\n\n0<grabIdThread(thread_12000_13000, initial)>\n\n0<grabIdThread(thread_13000_14000, initial)>\n\n0<grabIdThread(thread_14000_15000, initial)>\n\n0\n<grabIdThread(thread_15000_16000, initial)>\n0<grabIdThread(thread_16000_17000, initial)>\n\n0\n<grabIdThread(thread_17000_18000, initial)>\n0<grabIdThread(thread_18000_19000, initial)>\n\n0<grabIdThread(thread_19000_20000, initial)>\n\n0<grabIdThread(thread_20000_21000, initial)>\n\n0<grabIdThread(thread_21000_22000, initial)>\n\n0<grabIdThread(thread_22000_23000, initial)>\n\n0<grabIdThread(thread_23000_24000, initial)>\n\n0<grabIdThread(thread_24000_25000, initial)>\n\n0<grabIdThread(thread_25000_26000, initial)>\n\n0\n<grabIdThread(thread_26000_27000, initial)>\n0\n<grabIdThread(thread_27000_28000, initial)>\n0<grabIdThread(thread_28000_29000, initial)>\n\n0<grabIdThread(thread_29000_30000, initial)>\n0<grabIdThread(thread_30000_31000, initial)>\n\n\n0\n<grabIdThread(thread_31000_32000, initial)>\n0\n<grabIdThread(thread_32000_33000, initial)>\n0\n<grabIdThread(thread_33000_34000, initial)>\n0<grabIdThread(thread_34000_35000, initial)>\n\n0<grabIdThread(thread_35000_36000, initial)>\n0<grabIdThread(thread_36000_37000, initial)>\n\n\n0<grabIdThread(thread_37000_38000, initial)>\n\n0\n<grabIdThread(thread_38000_39000, initial)>\n0<grabIdThread(thread_39000_40000, initial)>\n\n0<grabIdThread(thread_40000_41000, initial)>\n0\n\n<grabIdThread(thread_41000_42000, initial)>\n0<grabIdThread(thread_42000_43000, initial)>\n\n0\n<grabIdThread(thread_43000_44000, initial)>\n0<grabIdThread(thread_44000_45000, initial)>\n\n0<grabIdThread(thread_45000_46000, initial)>\n0<grabIdThread(thread_46000_47000, initial)>\n\n\n0\n<grabIdThread(thread_47000_48000, initial)>\n0\n<grabIdThread(thread_48000_49000, initial)>\n0<grabIdThread(thread_49000_50000, initial)>\n\n0<grabIdThread(thread_50000_51000, initial)>\n\n0\n<grabIdThread(thread_51000_52000, initial)>\n0<grabIdThread(thread_52000_53000, initial)>\n\n0\n<grabIdThread(thread_53000_54000, initial)>\n0<grabIdThread(thread_54000_55000, initial)>\n0<grabIdThread(thread_55000_56000, initial)>\n\n\n0\n<grabIdThread(thread_56000_57000, initial)>\n0<grabIdThread(thread_57000_58000, initial)>\n\n0\n<grabIdThread(thread_58000_59000, initial)>\n0\n<grabIdThread(thread_59000_60000, initial)>\n0\n<grabIdThread(thread_60000_61000, initial)>\n0\n<grabIdThread(thread_61000_62000, initial)>\n0<grabIdThread(thread_62000_63000, initial)>\n\n0<grabIdThread(thread_63000_64000, initial)>\n\n0<grabIdThread(thread_64000_65000, initial)>\n\n0<grabIdThread(thread_65000_66000, initial)>\n\n0<grabIdThread(thread_66000_67000, initial)>\n0\n<grabIdThread(thread_67000_68000, initial)>\n\n0<grabIdThread(thread_68000_69000, initial)>\n\n0<grabIdThread(thread_69000_70000, initial)>\n\n0\n<grabIdThread(thread_70000_71000, initial)>\n0\n<grabIdThread(thread_71000_72000, initial)>\n0<grabIdThread(thread_72000_73000, initial)>\n\n0<grabIdThread(thread_73000_74000, initial)>\n\n0\n<grabIdThread(thread_74000_75000, initial)>\n0<grabIdThread(thread_75000_76000, initial)>\n0<grabIdThread(thread_76000_77000, initial)>\n\n\n0\n<grabIdThread(thread_77000_78000, initial)>\n0\n<grabIdThread(thread_78000_79000, initial)>\n0<grabIdThread(thread_79000_80000, initial)>\n\n0<grabIdThread(thread_80000_81000, initial)>\n\n0<grabIdThread(thread_81000_82000, initial)>\n\n0\n<grabIdThread(thread_82000_83000, initial)>\n0<grabIdThread(thread_83000_84000, initial)>\n\n0<grabIdThread(thread_84000_85000, initial)>\n\n0\n<grabIdThread(thread_85000_86000, initial)>\n0<grabIdThread(thread_86000_87000, initial)>\n\n0\n<grabIdThread(thread_87000_88000, initial)>\n0<grabIdThread(thread_88000_89000, initial)>\n\n0<grabIdThread(thread_89000_90000, initial)>\n0\n\n<grabIdThread(thread_90000_91000, initial)>\n0<grabIdThread(thread_91000_92000, initial)>\n\n0<grabIdThread(thread_92000_93000, initial)>\n\n0\n<grabIdThread(thread_93000_94000, initial)>\n0<grabIdThread(thread_94000_95000, initial)>\n0\n<grabIdThread(thread_95000_96000, initial)>\n\n0<grabIdThread(thread_96000_97000, initial)>\n\n0<grabIdThread(thread_97000_98000, initial)>\n\n0<grabIdThread(thread_98000_99000, initial)>\n\n0\n<grabIdThread(thread_99000_100000, initial)>\n0\n<grabIdThread(thread_100000_101000, initial)>\n0\n<grabIdThread(thread_101000_102000, initial)>\n0\n<grabIdThread(thread_102000_103000, initial)>\n0<grabIdThread(thread_103000_104000, initial)>\n0\n\n<grabIdThread(thread_104000_105000, initial)>\n0<grabIdThread(thread_105000_106000, initial)>\n\n0\n<grabIdThread(thread_106000_107000, initial)>\n0<grabIdThread(thread_107000_108000, initial)>\n0<grabIdThread(thread_108000_109000, initial)>\n0\n\n<grabIdThread(thread_109000_110000, initial)>\n\n0\n<grabIdThread(thread_110000_111000, initial)>\n0\n<grabIdThread(thread_111000_112000, initial)>\n0\n<grabIdThread(thread_112000_113000, initial)>\n0<grabIdThread(thread_113000_114000, initial)>\n0\n<grabIdThread(thread_114000_115000, initial)>\n0\n\n<grabIdThread(thread_115000_116000, initial)>\n0<grabIdThread(thread_116000_117000, initial)>\n0<grabIdThread(thread_117000_118000, initial)>\n\n0<grabIdThread(thread_118000_119000, initial)>\n\n0\n<grabIdThread(thread_119000_120000, initial)>\n\n0\n<grabIdThread(thread_120000_121000, initial)>\n0<grabIdThread(thread_121000_122000, initial)>\n\n0<grabIdThread(thread_122000_123000, initial)>\n0\n\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1007/s11127-016-0325-8 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1093/rfs/hhu039 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1007/s10640-014-9847-z (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1007/s00780-014-0246-7 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1007/s10490-013-9366-4 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1146/annurev-economics-080217-053207 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1016/j.cjar.2014.11.002 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1111/joac.12061 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1016/j.jinteco.2018.04.009 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1016/j.jbusres.2017.12.020 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1093/erae/jbt018 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1007/s10640-013-9749-5 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1057/fr.2015.7 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1080/01621459.2018.1514305 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1007/s10797-015-9364-1 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1080/00036846.2015.1117050 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1080/01621459.2017.1336443 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1016/j.retrec.2018.10.003 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1007/s00148-015-0552-1 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1111/roie.12140 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1111/more.12065 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1111/rssc.12188 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nConnectionError: HTTPSConnectionPool(host='api.altmetric.com', port=443): Max retries exceeded with url: /v1/doi/10.1002/hec.3399 (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\nReadTimeout: HTTPSConnectionPool(host='api.altmetric.com', port=443): Read timed out. (read timeout=10)\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500500\n\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500500\n\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n500\n"
    }
   ],
   "source": [
    "%%time\n",
    "step = 1000\n",
    "threads = []\n",
    "for i in range(0, 10):\n",
    "    for j in range(0, (int)(len(all_articles_df) / (step * 10))):\n",
    "        start_index = i * (int)(len(all_articles_df)/step)*(int)(step/10) + j * step\n",
    "        end_index = start_index + step\n",
    "        if end_index + step > len(all_articles_df):\n",
    "            end_index = len(all_articles_df)\n",
    "        \n",
    "        threadx = grabIdThread(j, f'thread_{start_index}_{end_index}', start_index, end_index)\n",
    "        print(threadx)\n",
    "        threadx.start()\n",
    "        threads.append(threadx)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "df = df.sort_index()\n",
    "df.to_csv(f'{origin_folder}/all_altmetric_id.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grab altmetric.com Details"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_detail_altmetric(doi, altmetric_id, so):\n",
    "    df = pd.DataFrame()\n",
    "    b_list = ['news outlets', 'blogs', 'policy', 'tweeters', 'weibo', 'facebook pages', 'wikipedia', 'redditors', 'f1000', 'video uploader', 'dimensions_citation', 'mendeley', 'citeulike']\n",
    "\n",
    "    df['DI'] = [doi]\n",
    "    df['altmetric_id'] = [altmetric_id]\n",
    "    if altmetric_id != '' and not math.isnan(altmetric_id):\n",
    "        altmetric_id = int(altmetric_id)\n",
    "        news_anchor = 'news</dt><dd><a href=\"/details/' + str(altmetric_id) + '/news\"><strong>'\n",
    "        blogs_anchor = 'blogs</dt><dd><a href=\"/details/' + str(altmetric_id) + '/blogs\"><strong>'\n",
    "        policy_anchor = 'policy</dt><dd><a href=\"/details/' + str(altmetric_id) + '/policy-documents\"><strong>'\n",
    "        twitter_anchor = 'twitter</dt><dd><a href=\"/details/' + str(altmetric_id) + '/twitter\"><strong>'\n",
    "        weibo_anchor = 'weibo</dt><dd><a href=\"/details/' + str(altmetric_id) + '/weibo\"><strong>'\n",
    "        facebook_anchor = 'facebook</dt><dd><a href=\"/details/' + str(altmetric_id) + '/facebook\"><strong>'\n",
    "        wikipedia_anchor = 'wikipedia</dt><dd><a href=\"/details/' + str(altmetric_id) + '/wikipedia\"><strong>'\n",
    "        redditors_anchor = 'reddit</dt><dd><a href=\"/details/' + str(altmetric_id) + '/reddit\"><strong>'\n",
    "        f1000_anchor = 'f1000</dt><dd><a href=\"/details/' + str(altmetric_id) + '/f1000\"><strong>'\n",
    "        video_anchor = 'video</dt><dd><a href=\"/details/' + str(altmetric_id) + '/video\"><strong>'\n",
    "        dimensions_citation_anchor = 'dimensions_citation</dt><dd><a href=\"/details/' + str(altmetric_id) + '/citations\"><strong>'\n",
    "        mendeley_anchor = 'mendeley</dt><dd><a href=\"/details/' + str(altmetric_id) + '#mendeley-demographics\"><strong>'\n",
    "        citeulike_anchor = 'citeulike</dt><dd><strong>'\n",
    "        c_list = [news_anchor, blogs_anchor, policy_anchor, twitter_anchor, weibo_anchor, facebook_anchor, wikipedia_anchor, redditors_anchor, f1000_anchor, video_anchor, dimensions_citation_anchor, mendeley_anchor, citeulike_anchor]\n",
    "\n",
    "        end_anchor = '</strong>'\n",
    "\n",
    "        res = grab_from_url_content('https://www.altmetric.com/details/' + str(altmetric_id))\n",
    "        if res is not None:\n",
    "\n",
    "            for i in range(0, len(c_list)):\n",
    "                start_index = res.find(c_list[i])\n",
    "                if start_index > 0:\n",
    "                    start_index += len(c_list[i])\n",
    "                    number = 0\n",
    "                    end_index = res.find(end_anchor, start_index, start_index + 100)\n",
    "                    number_temp = res[start_index: end_index]\n",
    "\n",
    "                    if number_temp is not '':\n",
    "                        number = number_temp\n",
    "                    df[b_list[i]] = int(number)\n",
    "                else:\n",
    "                    df[b_list[i]] = 0\n",
    "        else:\n",
    "            for i in range(0, len(b_list)):\n",
    "                df[b_list[i]] = 0\n",
    "    else:\n",
    "        for i in range(0, len(b_list)):\n",
    "            df[b_list[i]] = 0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_altmetric_detail_slice(start_index, end_index):\n",
    "    dfy =pd.DataFrame()\n",
    "\n",
    "    all_articles_df_slice = all_articles_df[start_index:end_index]\n",
    "    for index, row in all_articles_df_slice.iterrows():\n",
    "        if row['DI'] in df['DI'].values:\n",
    "            continue\n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        dfx = grab_detail_altmetric(row['DI'], row['altmetric_id'])\n",
    "        dfy = df.append(dfx, ignore_index=True)\n",
    "    return dfy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class grabDetailThread(threading.Thread):\n",
    "    def __init__(self, threadID, name, start_index, end_index):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.threadID = threadID\n",
    "        self.name = name\n",
    "        self.start_index = start_index\n",
    "        self.end_index = end_index\n",
    "    def run(self):\n",
    "        global df\n",
    "        dfy = grab_altmetric_detail_slice(self.start_index, self.end_index)\n",
    "        threadLock.acquire()\n",
    "        df = df.append(dfy)\n",
    "        threadLock.release()\n",
    "\n",
    "threadLock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_articles_df = pd.read_csv(f'{origin_folder}/all_altmetric_id.csv')\n",
    "df = pd.DataFrame(columns=['DI'])\n",
    "\n",
    "for i in range(0, 10):\n",
    "    for j in range(0, (int)(len(all_articles_df) / (step * 10))):\n",
    "        start_index = i * (int)(len(all_articles_df)/step)*(int)(step/10) + j * step\n",
    "        end_index = start_index + step\n",
    "        if end_index + step > len(all_articles_df):\n",
    "            end_index = len(all_articles_df)\n",
    "        \n",
    "        threadx = grabDetailThread(j, f'thread_{start_index}_{end_index}', start_index, end_index)\n",
    "        print(threadx)\n",
    "        threadx.start()\n",
    "        threads.append(threadx)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "df = df.sort_index()\n",
    "df.to_csv(f'{origin_folder}/all_altmetric_detail.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grab altmetric.com's Tweets Detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parser\n",
    "We will get the html content from the url which is not listed as we want it be, so we need parser to parse them into listed data, in json form."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class AltmetricHTMLParser(HTMLParser):\n",
    "    tweets = []\n",
    "    retweets = []\n",
    "    articles = {'tweets': tweets, 'retweets': retweets}\n",
    "    in_article = False\n",
    "    is_reply = False\n",
    "    has_article = False\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == 'body':\n",
    "            self.has_article = False\n",
    "        if tag == 'article':\n",
    "            self.has_article = True\n",
    "            self.in_article = True\n",
    "\n",
    "        if self.in_article and (tag == 'a'):\n",
    "            for attr in attrs:\n",
    "                if (attr[0] == 'class') and (attr[1] == 'reply'):\n",
    "                    self.is_reply = True\n",
    "                if self.is_reply and (attr[0] == 'href'):\n",
    "                    self.tweets.append(attr[1].split('=')[1])\n",
    "                    break\n",
    "        return\n",
    "                    \n",
    "    def handle_endtag(self, tag):\n",
    "        if tag == 'article':\n",
    "            self.in_article = False\n",
    "        self.is_reply = False\n",
    "        return\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        pass\n",
    "\n",
    "    def handle_comment(self, data):\n",
    "        pass\n",
    "\n",
    "    def handle_entityref(self, name):\n",
    "        pass\n",
    "\n",
    "    def handle_charref(self, name):\n",
    "        pass\n",
    "\n",
    "    def handle_decl(self, data):\n",
    "        pass\n",
    "\n",
    "parser = AltmetricHTMLParser()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "redirect_str = '<html><body>You are being <a href=\"https://www.altmetric.com/details/4236878\">redirected</a>.</body></html>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grab Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(f'{origin_folder}/all_altmetric_id.csv', usecols=['DI', 'altmetric_id'], dtype={'altmetric_id':str})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# articles_dict = {}\n",
    "# for index, row in df.iterrows():\n",
    "#     if row['altmetric_id'] == '' or str(row['altmetric_id']).lower() == 'nan':\n",
    "#         articles_dict[row['DI']] = {'altmetric_id': '', 'twitter_num': 0, 'tweets': []}\n",
    "#         continue\n",
    "#     # print(row['DI'], row['altmetric_id'])\n",
    "#     grab_url = f'https://www.altmetric.com/details/{row[\"altmetric_id\"]}/twitter/page:'\n",
    "#     print(str(index), grab_url)\n",
    "#     parser.articles = []\n",
    "#     for i in range(1, 100000):\n",
    "#         parser.feed(grab_from_url_content(grab_url + str(i), headers=headers))\n",
    "#         print('page: ', str(i))\n",
    "#         if not parser.has_article:\n",
    "#             break\n",
    "#     articles_dict[row['DI']] = {'altmetric_id': row['altmetric_id'], 'twitter_num': len(parser.articles), 'tweets': parser.articles}"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles_dict = {}\n",
    "def get_mention(source):\n",
    "    headers = {\n",
    "        'cookie': \"_ga=GA1.2.501259425.1572141776; weibo_license_acknowledgement=false; explorer_user=WWs2eDNOOUVjVHJTcHRjSm9Oc0ZuZEh0eDRkTmlPd0tCWFMzODNyNlIweFBvdjllM3RkcmF0RVdtRWdvRDN4Ny0tQlNpeTBsWU5NK0ZNTnFpK1FpVFUzdz09--8bac413ca9fd623b9918b311729130cfbb4e66e1; _altmetric-explorer_session=eExKU3g1UmJhWXpXbmVtS05YZmxVS3YyaVNDSGdPL2JyaWVYaE9mRTdPT3RlYlRLaTdrRmRWcnZpeFMrMFJLb0FIVDBvNHI3N09MWS9HZDhDRDdIbTZPZElvMWNPNzMvTm5JVkovWThiQVplZVdTRlZheDBWYWdvd2lIMXo2NHJUZkFJd2MxcWpZSmpCaXVXRW9CYlZnZ1l4L1lXMGhIa1k1d0o1bllvS09uWDBQb3JXMWUrazZ2YWVwaUwzei93cDdUZkhwanFtSy9lSkxLUmdRdEIrZz09LS1DckIxZFJZUVBWNmhsTEJXcWtkR2x3PT0%3D--884ad24217914b545556a68678c2d803c65ce9cf; intercom-session-9dnltu6y=alcwSlZxZHMzZlY3Wm8yaFpvWFg1OGxEYVZ4MXRRUDMrbkk1Q01Bdm5XNXJkQXNZcVAyeEZYVHFYS3RUbWJSbi0tclFPUDlZcUVpMFZKQVlxdlMwRllVQT09--46bb4ebcf64063d6a3712dd82a1d2bff57eed87f, _ga=GA1.2.501259425.1572141776; weibo_license_acknowledgement=false; explorer_user=WWs2eDNOOUVjVHJTcHRjSm9Oc0ZuZEh0eDRkTmlPd0tCWFMzODNyNlIweFBvdjllM3RkcmF0RVdtRWdvRDN4Ny0tQlNpeTBsWU5NK0ZNTnFpK1FpVFUzdz09--8bac413ca9fd623b9918b311729130cfbb4e66e1; _altmetric-explorer_session=eExKU3g1UmJhWXpXbmVtS05YZmxVS3YyaVNDSGdPL2JyaWVYaE9mRTdPT3RlYlRLaTdrRmRWcnZpeFMrMFJLb0FIVDBvNHI3N09MWS9HZDhDRDdIbTZPZElvMWNPNzMvTm5JVkovWThiQVplZVdTRlZheDBWYWdvd2lIMXo2NHJUZkFJd2MxcWpZSmpCaXVXRW9CYlZnZ1l4L1lXMGhIa1k1d0o1bllvS09uWDBQb3JXMWUrazZ2YWVwaUwzei93cDdUZkhwanFtSy9lSkxLUmdRdEIrZz09LS1DckIxZFJZUVBWNmhsTEJXcWtkR2x3PT0%3D--884ad24217914b545556a68678c2d803c65ce9cf; intercom-session-9dnltu6y=alcwSlZxZHMzZlY3Wm8yaFpvWFg1OGxEYVZ4MXRRUDMrbkk1Q01Bdm5XNXJkQXNZcVAyeEZYVHFYS3RUbWJSbi0tclFPUDlZcUVpMFZKQVlxdlMwRllVQT09--46bb4ebcf64063d6a3712dd82a1d2bff57eed87f; Cookie_1=value\",\n",
    "        'User-Agent': \"PostmanRuntime/7.19.0\",\n",
    "        'Accept': \"*/*\",\n",
    "        'Cache-Control': \"no-cache\",\n",
    "        'Postman-Token': \"30d13c93-aa9a-44e1-84e0-8876f98ae1ba,b45c8eb6-7f77-4c48-b961-921c89280079\",\n",
    "        'Host': \"www.altmetric.com\",\n",
    "        'Accept-Encoding': \"gzip, deflate\",\n",
    "        'Connection': \"keep-alive\",\n",
    "        'cache-control': \"no-cache\"\n",
    "    }\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['DI'] in articles_dict:\n",
    "            continue\n",
    "        if index % 100 == 0:\n",
    "            print(str(index))\n",
    "        if row['DI'] == '' or str(row['DI']).lower() == 'nan' or row['altmetric_id'] == '' or str(row['altmetric_id']).lower() == 'nan':\n",
    "            articles_dict[row['DI']] = {'altmetric_id': '', f'{source}_num': 0, f'{source}s': []}\n",
    "            continue\n",
    "\n",
    "        articles = []\n",
    "        grab_url = f'https://www.altmetric.com/explorer/json_data/mentions?identifier={row[\"DI\"]}&mention_sources%5B%5D=type%3A{source}&scope=all&page='\n",
    "        for i in range(1, 100000):\n",
    "            articles_json = grab_from_url_json(grab_url + str(i), headers=headers)\n",
    "            articles.extend(articles_json['data'])\n",
    "            # print('page: ', str(i))\n",
    "            if articles_json['lastPage']:\n",
    "                break\n",
    "            \n",
    "        articles_dict[row['DI']] = {'altmetric_id': row['altmetric_id'], f'{source}_num': len(articles), f'{source}s': articles}\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_mention('tweet')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{origin_folder}/article_tweets_altmetric.json', \"w+\") as dump_f:\n",
    "    dump_f.write(json.dumps(articles_dict))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(articles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{origin_folder}/article_tweets_altmetric.json', \"r\") as f:\n",
    "    article_tweets = json.load(f)\n",
    "\n",
    "df_tweets = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for doi in article_tweets:\n",
    "    for tweet_chain in article_tweets[doi]['tweets']:\n",
    "        for tweet in tweet_chain[1]:\n",
    "            if tweet['url'] in df_tweets['tweet_url']:\n",
    "                continue\n",
    "            df_tweet = pd.DataFrame(columns=['doi', 'altmetric_id', 'tweet_id', 'tweet_url', 'postedAt', 'postType', 'originalPost'])\n",
    "            df_tweet['doi'] = [doi]\n",
    "            df_tweet['altmetric_id'] = [article_tweets[doi]['altmetric_id']]\n",
    "            df_tweet['tweet_id'] = [str(tweet['url']).split('/')[-1]]\n",
    "            df_tweet['tweet_url'] = [tweet['url']]\n",
    "            df_tweet['postedAt'] = [tweet['postedAt']]\n",
    "            df_tweet['postType'] = [tweet['postType']]\n",
    "            df_tweet['originalPost'] = [str(tweet['originalPost'])]\n",
    "\n",
    "            df_tweets = df_tweets.append(df_tweet, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.to_csv(f'{origin_folder}/article_tweets_altmetric.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(f'{origin_folder}/all_altmetric_detail.csv')\n",
    "df_tweets = pd.read_csv(f'{origin_folder}/article_tweets_altmetric.csv')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_count = df_tweets.groupby(by=['doi'])['altmetric_id'].count()\n",
    "df_all = df_all.merge(df_tweets_count, left_on=['DI'], right_on=['doi'], how='left', suffixes=['', '_tweets_count'])\n",
    "df_all['altmetric_id_tweets_count'] = df_all['altmetric_id_tweets_count'].fillna(0)\n",
    "df_all = df_all.rename({'altmetric_id_tweets_count': 'tweets_count'}, axis=1)\n",
    "df_tweets_count = df_tweets[df_tweets['originalPost'] == True].groupby(by=['doi'])['altmetric_id'].count()\n",
    "df_all = df_all.merge(df_tweets_count, left_on=['DI'], right_on=['doi'], how='left', suffixes=['', '_tweets_origin_count'])\n",
    "df_all['altmetric_id_tweets_origin_count'] = df_all['altmetric_id_tweets_origin_count'].fillna(0)\n",
    "df_all = df_all.rename({'altmetric_id_tweets_origin_count': 'tweets_origin_count'}, axis=1)\n",
    "df_all\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_info = pd.read_csv(f'{origin_folder}/all.csv', usecols=['DI', 'SO', 'TC'])\n",
    "df_all = df_all.merge(all_info, on='DI', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(f'{origin_folder}/all_altmetric_detail.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "articles_dict = {}\n",
    "get_mention('fbwall')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{origin_folder}/article_fbwalls_altmetric.json', \"w+\") as dump_f:\n",
    "    dump_f.write(json.dumps(articles_dict))"
   ]
  }
 ]
}