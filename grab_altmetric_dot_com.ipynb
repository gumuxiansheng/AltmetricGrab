{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab Altmetric.com Data"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Request Functions\n",
    "This part contains functions we need to fetch the web data and should also handle the exceptions while fetching here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grab_util import *\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_folder = 'data/outputs/OR'"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grab altmetric.com Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_altmetric_id(doi):\n",
    "    detail_id = ''\n",
    "    res = grab_from_url_json('https://api.altmetric.com/v1/doi/' + doi)\n",
    "    if res is not None:\n",
    "        detail_id = res['altmetric_id']\n",
    "    return detail_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles_df = pd.read_excel(f'{origin_folder}/all.xlsx', usecols=['SO', 'DI'])\n",
    "df = pd.DataFrame(columns=['DI', 'altmetric_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for index, doi in enumerate(all_articles_df['DI']):\n",
    "    if doi in df['DI'].values:\n",
    "        continue\n",
    "    if index % 100 == 0:\n",
    "        print(index)\n",
    "    dfx = pd.DataFrame(columns=['DI', 'altmetric_id'])\n",
    "    dfx['DI'] = [doi]\n",
    "    dfx['altmetric_id'] = [get_altmetric_id(str(doi))]\n",
    "    df = df.append(dfx, ignore_index=True)\n",
    "\n",
    "df.to_csv(f'{origin_folder}/all_altmetric_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grab altmetric.com Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_detail_altmetric(doi, altmetric_id):\n",
    "    df = pd.DataFrame()\n",
    "    b_list = ['news outlets', 'blogs', 'policy', 'tweeters', 'weibo', 'facebook pages', 'wikipedia', 'redditors', 'f1000', 'video uploader', 'dimensions_citation', 'mendeley', 'citeulike']\n",
    "\n",
    "    df['DI'] = [doi]\n",
    "    df['altmetric_id'] = [altmetric_id]\n",
    "    if altmetric_id != '' and not math.isnan(altmetric_id):\n",
    "        altmetric_id = int(altmetric_id)\n",
    "        news_anchor = 'news</dt><dd><a href=\"/details/' + str(altmetric_id) + '/news\"><strong>'\n",
    "        blogs_anchor = 'blogs</dt><dd><a href=\"/details/' + str(altmetric_id) + '/blogs\"><strong>'\n",
    "        policy_anchor = 'policy</dt><dd><a href=\"/details/' + str(altmetric_id) + '/policy-documents\"><strong>'\n",
    "        twitter_anchor = 'twitter</dt><dd><a href=\"/details/' + str(altmetric_id) + '/twitter\"><strong>'\n",
    "        weibo_anchor = 'weibo</dt><dd><a href=\"/details/' + str(altmetric_id) + '/weibo\"><strong>'\n",
    "        facebook_anchor = 'facebook</dt><dd><a href=\"/details/' + str(altmetric_id) + '/facebook\"><strong>'\n",
    "        wikipedia_anchor = 'wikipedia</dt><dd><a href=\"/details/' + str(altmetric_id) + '/wikipedia\"><strong>'\n",
    "        redditors_anchor = 'reddit</dt><dd><a href=\"/details/' + str(altmetric_id) + '/reddit\"><strong>'\n",
    "        f1000_anchor = 'f1000</dt><dd><a href=\"/details/' + str(altmetric_id) + '/f1000\"><strong>'\n",
    "        video_anchor = 'video</dt><dd><a href=\"/details/' + str(altmetric_id) + '/video\"><strong>'\n",
    "        dimensions_citation_anchor = 'dimensions_citation</dt><dd><a href=\"/details/' + str(altmetric_id) + '/citations\"><strong>'\n",
    "        mendeley_anchor = 'mendeley</dt><dd><a href=\"/details/' + str(altmetric_id) + '#mendeley-demographics\"><strong>'\n",
    "        citeulike_anchor = 'citeulike</dt><dd><strong>'\n",
    "        c_list = [news_anchor, blogs_anchor, policy_anchor, twitter_anchor, weibo_anchor, facebook_anchor, wikipedia_anchor, redditors_anchor, f1000_anchor, video_anchor, dimensions_citation_anchor, mendeley_anchor, citeulike_anchor]\n",
    "\n",
    "        end_anchor = '</strong>'\n",
    "\n",
    "        res = grab_from_url_content('https://www.altmetric.com/details/' + str(altmetric_id))\n",
    "        if res is not None:\n",
    "\n",
    "            for i in range(0, len(c_list)):\n",
    "                start_index = res.find(c_list[i])\n",
    "                if start_index > 0:\n",
    "                    start_index += len(c_list[i])\n",
    "                    number = 0\n",
    "                    end_index = res.find(end_anchor, start_index, start_index + 100)\n",
    "                    number_temp = res[start_index: end_index]\n",
    "\n",
    "                    if number_temp is not '':\n",
    "                        number = number_temp\n",
    "                    df[b_list[i]] = int(number)\n",
    "                else:\n",
    "                    df[b_list[i]] = 0\n",
    "        else:\n",
    "            for i in range(0, len(b_list)):\n",
    "                df[b_list[i]] = 0\n",
    "    else:\n",
    "        for i in range(0, len(b_list)):\n",
    "            df[b_list[i]] = 0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_articles_df = pd.read_csv(f'{origin_folder}/all_altmetric_id.csv')\n",
    "df = pd.DataFrame(columns=['DI'])\n",
    "for index, row in all_articles_df.iterrows():\n",
    "    if row['DI'] in df['DI'].values:\n",
    "        continue\n",
    "    if index % 100 == 0:\n",
    "        print(index)\n",
    "    dfx = grab_detail_altmetric(row['DI'], row['altmetric_id'])\n",
    "    df = df.append(dfx, ignore_index=True)\n",
    "\n",
    "df.to_csv(f'{origin_folder}/all_altmetric_detail.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grab altmetric.com's Tweets Detail"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parser\n",
    "We will get the html content from the url which is not listed as we want it be, so we need parser to parse them into listed data, in json form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class AltmetricHTMLParser(HTMLParser):\n",
    "    tweets = []\n",
    "    retweets = []\n",
    "    articles = {'tweets': tweets, 'retweets': retweets}\n",
    "    in_article = False\n",
    "    is_reply = False\n",
    "    has_article = False\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == 'body':\n",
    "            self.has_article = False\n",
    "        if tag == 'article':\n",
    "            self.has_article = True\n",
    "            self.in_article = True\n",
    "\n",
    "        if self.in_article and (tag == 'a'):\n",
    "            for attr in attrs:\n",
    "                if (attr[0] == 'class') and (attr[1] == 'reply'):\n",
    "                    self.is_reply = True\n",
    "                if self.is_reply and (attr[0] == 'href'):\n",
    "                    self.tweets.append(attr[1].split('=')[1])\n",
    "                    break\n",
    "        return\n",
    "                    \n",
    "    def handle_endtag(self, tag):\n",
    "        if tag == 'article':\n",
    "            self.in_article = False\n",
    "        self.is_reply = False\n",
    "        return\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        pass\n",
    "\n",
    "    def handle_comment(self, data):\n",
    "        pass\n",
    "\n",
    "    def handle_entityref(self, name):\n",
    "        pass\n",
    "\n",
    "    def handle_charref(self, name):\n",
    "        pass\n",
    "\n",
    "    def handle_decl(self, data):\n",
    "        pass\n",
    "\n",
    "parser = AltmetricHTMLParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "redirect_str = '<html><body>You are being <a href=\"https://www.altmetric.com/details/4236878\">redirected</a>.</body></html>'"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grab Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DI</th>\n      <th>altmetric_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.1007/s10479-015-1981-7</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.1007/s10479-015-1987-1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.1007/s10479-015-1880-y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.1007/s10479-015-1958-6</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10.1007/s10479-015-1935-0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10.1007/s10479-015-1905-6</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10.1007/s10479-015-1997-z</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>10.1007/s10479-015-2010-6</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10.1007/s10479-015-1913-6</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10.1007/s10479-015-1925-2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10.1007/s10479-015-1951-0</td>\n      <td>8700004</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10.1007/s10479-015-1990-6</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>10.1007/s10479-015-1962-x</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>10.1007/s10479-015-1918-1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>10.1007/s10479-015-1877-6</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>10.1007/s10479-015-1932-3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>10.1007/s10479-014-1727-y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>10.1007/s10479-014-1777-1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10.1007/s10479-014-1550-5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>10.1007/s10479-014-1779-z</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>10.1007/s10479-012-1253-8</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>10.1007/s10479-014-1595-5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>10.1007/s10479-014-1574-x</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>10.1007/s10479-014-1656-9</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>10.1007/s10479-013-1443-z</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>10.1007/s10479-013-1507-0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>10.1007/s10479-013-1407-3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>10.1007/s10479-013-1516-z</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>10.1007/s10479-014-1566-x</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>10.1007/s10479-013-1316-5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6730</th>\n      <td>10.1016/j.disopt.2015.07.002</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6731</th>\n      <td>10.1016/j.disopt.2015.07.004</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6732</th>\n      <td>10.1016/j.disopt.2015.07.003</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6733</th>\n      <td>10.1016/j.disopt.2015.09.001</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6734</th>\n      <td>10.1016/j.disopt.2015.08.001</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6735</th>\n      <td>10.1016/j.disopt.2015.09.007</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6736</th>\n      <td>10.1016/j.disopt.2015.09.002</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6737</th>\n      <td>10.1016/j.disopt.2015.09.005</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6738</th>\n      <td>10.1016/j.disopt.2015.10.001</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6739</th>\n      <td>10.1016/j.disopt.2015.10.002</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6740</th>\n      <td>10.1016/j.disopt.2015.09.006</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6741</th>\n      <td>10.1016/j.disopt.2015.03.001</td>\n      <td>21511158</td>\n    </tr>\n    <tr>\n      <th>6742</th>\n      <td>10.1016/j.disopt.2014.10.001</td>\n      <td>21511160</td>\n    </tr>\n    <tr>\n      <th>6743</th>\n      <td>10.1016/j.disopt.2015.03.003</td>\n      <td>21511159</td>\n    </tr>\n    <tr>\n      <th>6744</th>\n      <td>10.1016/j.disopt.2015.04.001</td>\n      <td>21511162</td>\n    </tr>\n    <tr>\n      <th>6745</th>\n      <td>10.1016/j.disopt.2015.05.001</td>\n      <td>21511155</td>\n    </tr>\n    <tr>\n      <th>6746</th>\n      <td>10.1016/j.disopt.2015.05.002</td>\n      <td>21511156</td>\n    </tr>\n    <tr>\n      <th>6747</th>\n      <td>10.1016/j.disopt.2015.05.003</td>\n      <td>21511157</td>\n    </tr>\n    <tr>\n      <th>6748</th>\n      <td>10.1016/j.disopt.2015.06.001</td>\n      <td>21511161</td>\n    </tr>\n    <tr>\n      <th>6749</th>\n      <td>10.1016/j.disopt.2014.12.001</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6750</th>\n      <td>10.1016/j.disopt.2014.12.003</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6751</th>\n      <td>10.1016/j.disopt.2015.01.001</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6752</th>\n      <td>10.1016/j.disopt.2015.01.002</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6753</th>\n      <td>10.1016/j.disopt.2015.02.001</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6754</th>\n      <td>10.1016/j.disopt.2015.02.003</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6755</th>\n      <td>10.1016/j.disopt.2014.12.002</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6756</th>\n      <td>10.1016/j.disopt.2014.08.002</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6757</th>\n      <td>10.1016/j.disopt.2014.11.002</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6758</th>\n      <td>10.1016/j.disopt.2014.11.003</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6759</th>\n      <td>10.1016/j.disopt.2014.11.001</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>6760 rows × 2 columns</p>\n</div>",
      "text/plain": "                                DI altmetric_id\n0        10.1007/s10479-015-1981-7          NaN\n1        10.1007/s10479-015-1987-1          NaN\n2        10.1007/s10479-015-1880-y          NaN\n3        10.1007/s10479-015-1958-6          NaN\n4        10.1007/s10479-015-1935-0          NaN\n5        10.1007/s10479-015-1905-6          NaN\n6        10.1007/s10479-015-1997-z          NaN\n7        10.1007/s10479-015-2010-6          NaN\n8        10.1007/s10479-015-1913-6          NaN\n9        10.1007/s10479-015-1925-2          NaN\n10       10.1007/s10479-015-1951-0      8700004\n11       10.1007/s10479-015-1990-6          NaN\n12       10.1007/s10479-015-1962-x          NaN\n13       10.1007/s10479-015-1918-1          NaN\n14       10.1007/s10479-015-1877-6          NaN\n15       10.1007/s10479-015-1932-3          NaN\n16       10.1007/s10479-014-1727-y          NaN\n17       10.1007/s10479-014-1777-1          NaN\n18       10.1007/s10479-014-1550-5          NaN\n19       10.1007/s10479-014-1779-z          NaN\n20       10.1007/s10479-012-1253-8          NaN\n21       10.1007/s10479-014-1595-5          NaN\n22       10.1007/s10479-014-1574-x          NaN\n23       10.1007/s10479-014-1656-9          NaN\n24       10.1007/s10479-013-1443-z          NaN\n25       10.1007/s10479-013-1507-0          NaN\n26       10.1007/s10479-013-1407-3          NaN\n27       10.1007/s10479-013-1516-z          NaN\n28       10.1007/s10479-014-1566-x          NaN\n29       10.1007/s10479-013-1316-5          NaN\n...                            ...          ...\n6730  10.1016/j.disopt.2015.07.002          NaN\n6731  10.1016/j.disopt.2015.07.004          NaN\n6732  10.1016/j.disopt.2015.07.003          NaN\n6733  10.1016/j.disopt.2015.09.001          NaN\n6734  10.1016/j.disopt.2015.08.001          NaN\n6735  10.1016/j.disopt.2015.09.007          NaN\n6736  10.1016/j.disopt.2015.09.002          NaN\n6737  10.1016/j.disopt.2015.09.005          NaN\n6738  10.1016/j.disopt.2015.10.001          NaN\n6739  10.1016/j.disopt.2015.10.002          NaN\n6740  10.1016/j.disopt.2015.09.006          NaN\n6741  10.1016/j.disopt.2015.03.001     21511158\n6742  10.1016/j.disopt.2014.10.001     21511160\n6743  10.1016/j.disopt.2015.03.003     21511159\n6744  10.1016/j.disopt.2015.04.001     21511162\n6745  10.1016/j.disopt.2015.05.001     21511155\n6746  10.1016/j.disopt.2015.05.002     21511156\n6747  10.1016/j.disopt.2015.05.003     21511157\n6748  10.1016/j.disopt.2015.06.001     21511161\n6749  10.1016/j.disopt.2014.12.001          NaN\n6750  10.1016/j.disopt.2014.12.003          NaN\n6751  10.1016/j.disopt.2015.01.001          NaN\n6752  10.1016/j.disopt.2015.01.002          NaN\n6753  10.1016/j.disopt.2015.02.001          NaN\n6754  10.1016/j.disopt.2015.02.003          NaN\n6755  10.1016/j.disopt.2014.12.002          NaN\n6756  10.1016/j.disopt.2014.08.002          NaN\n6757  10.1016/j.disopt.2014.11.002          NaN\n6758  10.1016/j.disopt.2014.11.003          NaN\n6759  10.1016/j.disopt.2014.11.001          NaN\n\n[6760 rows x 2 columns]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(f'{origin_folder}/all_altmetric_id.csv', usecols=['DI', 'altmetric_id'], dtype={'altmetric_id':str})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'cookie': \"_ga=GA1.2.501259425.1572141776; weibo_license_acknowledgement=false; explorer_user=WWs2eDNOOUVjVHJTcHRjSm9Oc0ZuZEh0eDRkTmlPd0tCWFMzODNyNlIweFBvdjllM3RkcmF0RVdtRWdvRDN4Ny0tQlNpeTBsWU5NK0ZNTnFpK1FpVFUzdz09--8bac413ca9fd623b9918b311729130cfbb4e66e1; _altmetric-explorer_session=eExKU3g1UmJhWXpXbmVtS05YZmxVS3YyaVNDSGdPL2JyaWVYaE9mRTdPT3RlYlRLaTdrRmRWcnZpeFMrMFJLb0FIVDBvNHI3N09MWS9HZDhDRDdIbTZPZElvMWNPNzMvTm5JVkovWThiQVplZVdTRlZheDBWYWdvd2lIMXo2NHJUZkFJd2MxcWpZSmpCaXVXRW9CYlZnZ1l4L1lXMGhIa1k1d0o1bllvS09uWDBQb3JXMWUrazZ2YWVwaUwzei93cDdUZkhwanFtSy9lSkxLUmdRdEIrZz09LS1DckIxZFJZUVBWNmhsTEJXcWtkR2x3PT0%3D--884ad24217914b545556a68678c2d803c65ce9cf; intercom-session-9dnltu6y=alcwSlZxZHMzZlY3Wm8yaFpvWFg1OGxEYVZ4MXRRUDMrbkk1Q01Bdm5XNXJkQXNZcVAyeEZYVHFYS3RUbWJSbi0tclFPUDlZcUVpMFZKQVlxdlMwRllVQT09--46bb4ebcf64063d6a3712dd82a1d2bff57eed87f, _ga=GA1.2.501259425.1572141776; weibo_license_acknowledgement=false; explorer_user=WWs2eDNOOUVjVHJTcHRjSm9Oc0ZuZEh0eDRkTmlPd0tCWFMzODNyNlIweFBvdjllM3RkcmF0RVdtRWdvRDN4Ny0tQlNpeTBsWU5NK0ZNTnFpK1FpVFUzdz09--8bac413ca9fd623b9918b311729130cfbb4e66e1; _altmetric-explorer_session=eExKU3g1UmJhWXpXbmVtS05YZmxVS3YyaVNDSGdPL2JyaWVYaE9mRTdPT3RlYlRLaTdrRmRWcnZpeFMrMFJLb0FIVDBvNHI3N09MWS9HZDhDRDdIbTZPZElvMWNPNzMvTm5JVkovWThiQVplZVdTRlZheDBWYWdvd2lIMXo2NHJUZkFJd2MxcWpZSmpCaXVXRW9CYlZnZ1l4L1lXMGhIa1k1d0o1bllvS09uWDBQb3JXMWUrazZ2YWVwaUwzei93cDdUZkhwanFtSy9lSkxLUmdRdEIrZz09LS1DckIxZFJZUVBWNmhsTEJXcWtkR2x3PT0%3D--884ad24217914b545556a68678c2d803c65ce9cf; intercom-session-9dnltu6y=alcwSlZxZHMzZlY3Wm8yaFpvWFg1OGxEYVZ4MXRRUDMrbkk1Q01Bdm5XNXJkQXNZcVAyeEZYVHFYS3RUbWJSbi0tclFPUDlZcUVpMFZKQVlxdlMwRllVQT09--46bb4ebcf64063d6a3712dd82a1d2bff57eed87f; Cookie_1=value\",\n",
    "    'User-Agent': \"PostmanRuntime/7.19.0\",\n",
    "    'Accept': \"*/*\",\n",
    "    'Cache-Control': \"no-cache\",\n",
    "    'Postman-Token': \"30d13c93-aa9a-44e1-84e0-8876f98ae1ba,b45c8eb6-7f77-4c48-b961-921c89280079\",\n",
    "    'Host': \"www.altmetric.com\",\n",
    "    'Accept-Encoding': \"gzip, deflate\",\n",
    "    'Connection': \"keep-alive\",\n",
    "    'cache-control': \"no-cache\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# articles_dict = {}\n",
    "# for index, row in df.iterrows():\n",
    "#     if row['altmetric_id'] == '' or str(row['altmetric_id']).lower() == 'nan':\n",
    "#         articles_dict[row['DI']] = {'altmetric_id': '', 'twitter_num': 0, 'tweets': []}\n",
    "#         continue\n",
    "#     # print(row['DI'], row['altmetric_id'])\n",
    "#     grab_url = f'https://www.altmetric.com/details/{row[\"altmetric_id\"]}/twitter/page:'\n",
    "#     print(str(index), grab_url)\n",
    "#     parser.articles = []\n",
    "#     for i in range(1, 100000):\n",
    "#         parser.feed(grab_from_url_content(grab_url + str(i), headers=headers))\n",
    "#         print('page: ', str(i))\n",
    "#         if not parser.has_article:\n",
    "#             break\n",
    "#     articles_dict[row['DI']] = {'altmetric_id': row['altmetric_id'], 'twitter_num': len(parser.articles), 'tweets': parser.articles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1100\n1200\n1300\n1400\n1500\n1600\n1700\n1800\n1900\n2000\n2100\n2200\n2300\n2400\n2500\n2600\n2700\n2800\n2900\n3000\n3100\n3200\n3300\n3400\n3500\n3600\n3700\n3800\n3900\n4000\n4100\n4200\n4300\n4400\n4500\n4600\n4700\n4800\n4900\n5000\n5100\n5200\n5300\n5400\n5500\n5600\n5700\n5800\n5900\n6000\n6100\n6200\n6300\n6400\n6500\n6600\n6700\nCPU times: user 29.1 s, sys: 1.89 s, total: 31 s\nWall time: 29min 46s\n"
    }
   ],
   "source": [
    "%%time\n",
    "articles_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    if index % 100 == 0:\n",
    "        print(str(index), end='\\r')\n",
    "    if row['DI'] == '' or str(row['DI']).lower() == 'nan' or row['altmetric_id'] == '' or str(row['altmetric_id']).lower() == 'nan':\n",
    "        articles_dict[row['DI']] = {'altmetric_id': '', 'twitter_num': 0, 'tweets': []}\n",
    "        continue\n",
    "\n",
    "    articles = []\n",
    "    grab_url = f'https://www.altmetric.com/explorer/json_data/mentions?identifier={row[\"DI\"]}&mention_sources%5B%5D=type%3Atweet&scope=all&page='\n",
    "    for i in range(1, 100000):\n",
    "        articles_json = grab_from_url_json(grab_url + str(i), headers=headers)\n",
    "        articles.extend(articles_json['data'])\n",
    "        # print('page: ', str(i))\n",
    "        if articles_json['lastPage']:\n",
    "            break\n",
    "        \n",
    "    articles_dict[row['DI']] = {'altmetric_id': row['altmetric_id'], 'twitter_num': len(articles), 'tweets': articles}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{origin_folder}/article_tweets_altmetric_x.json', \"w+\") as dump_f:\n",
    "    dump_f.write(json.dumps(articles_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}