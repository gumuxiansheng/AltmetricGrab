{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab Dimensions Data\n",
    "\n",
    "https://app.dimensions.ai/discover/publication\n",
    "\n",
    "This notebook handles the downloads of Dimensions data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_folder = 'SUSTC_Journals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals_file = f'{origin_folder}/WOS期刊汇总_DimentionsSearch.csv'\n",
    "ori_journals = pd.read_csv(journals_file, usecols=['search title', 'search id'])\n",
    "ori_journals = ori_journals.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ori_journals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "end_index = 38\n",
    "sep_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_journals"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Request Functions\n",
    "\n",
    "This part contains functions we need to fetch the web data and should also handle the exceptions while fetching here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from requests import ConnectionError, ReadTimeout\n",
    "\n",
    "def grab_from_url_content(url):\n",
    "    headers = {'Accept': '* / *',\n",
    "               'Accept-Language': 'zh-TW, zh; q=0.9, en-US; q=0.8, en; q=0.7, zh-CN; q=0.6',\n",
    "               'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3610.2 Safari/537.36'\n",
    "               }\n",
    "    rescontent = ''\n",
    "    try:\n",
    "        res = requests.get(url, headers=headers, timeout=10)\n",
    "        rescontent = res.text\n",
    "    except ConnectionError as ce:\n",
    "        print('ConnectionError: ' + str(ce))\n",
    "        return grab_from_url_content(url)\n",
    "    except ReadTimeout as rte:\n",
    "        print('ReadTimeout: ' + str(rte))\n",
    "        return grab_from_url_content(url)\n",
    "\n",
    "    return rescontent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parser\n",
    "\n",
    "We will get the html content from the url which is not listed as we want it be, so we need parser to parse them into listed data, in json form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class DimensionsHTMLParser(HTMLParser):\n",
    "    articles = []\n",
    "    in_article = False\n",
    "    is_next_trigger = False\n",
    "    next_trigger_url = ''\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == 'article':\n",
    "            self.in_article = True\n",
    "        \n",
    "        if self.in_article:\n",
    "            for attr in attrs:\n",
    "                if attr[0] == 'data-doc':\n",
    "                    self.articles.append(json.loads(attr[1]))\n",
    "                    break\n",
    "\n",
    "        if tag == 'a':\n",
    "            for attr in attrs:\n",
    "                if (attr[0] == 'class') and (attr[1] == 'nextPage-trigger'):\n",
    "                    self.is_next_trigger = True\n",
    "                if self.is_next_trigger and (attr[0] == 'href'):\n",
    "                    self.next_trigger_url = f'https://app.dimensions.ai{attr[1]}&{search_params}'\n",
    "                    break\n",
    "        return\n",
    "                    \n",
    "    def handle_endtag(self, tag):\n",
    "        if tag == 'article':\n",
    "            self.in_article = False\n",
    "        self.is_next_trigger = False\n",
    "        return\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        pass\n",
    "\n",
    "    def handle_comment(self, data):\n",
    "        pass\n",
    "\n",
    "    def handle_entityref(self, name):\n",
    "        pass\n",
    "\n",
    "    def handle_charref(self, name):\n",
    "        pass\n",
    "\n",
    "    def handle_decl(self, data):\n",
    "        pass\n",
    "    \n",
    "parser = DimensionsHTMLParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grab Data\n",
    "\n",
    "The data fetching starts from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if end_index > int(len(ori_journals) / sep_len):\n",
    "    end_index = int(len(ori_journals) / sep_len)\n",
    "for l in range(start_index, end_index):\n",
    "    parser.articles = []\n",
    "\n",
    "    journals_index = str(1 + l * sep_len) + '-' + str((l + 1) * sep_len)\n",
    "    start = int(journals_index.split('-')[0])\n",
    "    end = int(journals_index.split('-')[1])\n",
    "    if end < len(ori_journals):\n",
    "        journals = ori_journals[start - 1:end]\n",
    "    else:\n",
    "        journals = ori_journals[start - 1:]\n",
    "    print(journals_index)\n",
    "\n",
    "    for index, row in journals.iterrows():\n",
    "        journal_search = row['search id']\n",
    "        # This is very important for data fetching, generally you get url in the form as 'https://app.dimensions.ai/discover/publication?and_facet_for=2209&and_facet_for=2202&or_facet_source_title=jour.1082997', and search_params is just the substring after '?'.\n",
    "        # Here is where we need to change for each search.\n",
    "        search_params = f'or_facet_year=2014&or_facet_year=2015&or_facet_year=2016&or_facet_year=2017&or_facet_year=2018&or_facet_source_title={journal_search}'\n",
    "        grab_url = f'https://app.dimensions.ai/discover/publication.contents.html?{search_params}'\n",
    "        print(grab_url)\n",
    "\n",
    "        parser.feed(grab_from_url_content(grab_url))\n",
    "        next_trigger_anchor = ''\n",
    "        i = 0\n",
    "        while parser.next_trigger_url != next_trigger_anchor:\n",
    "            if i % 10 == 0:\n",
    "                print(str(i))\n",
    "            i+=1\n",
    "            next_trigger_anchor = parser.next_trigger_url\n",
    "            parser.feed(grab_from_url_content(parser.next_trigger_url))\n",
    "    \n",
    "    print(len(parser.articles))\n",
    "    with open(f\"{origin_folder}/articles_wos_{journals_index}.json\", \"w\") as dump_f:\n",
    "        dump_f.write(json.dumps(parser.articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_folder = origin_folder + '/articles_wos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# for l in range(2, int(len(ori_journals) / sep_len)):\n",
    "for journals_index in ['1-200', '3801-3900']:\n",
    "    # journals_index = str(1 + l * sep_len) + '-' + str((l + 1) * sep_len)\n",
    "    with open(f'{origin_folder}/articles_wos_{journals_index}.json') as f:\n",
    "        articles = json.load(f)\n",
    "\n",
    "    columns_extract = ['SO', 'SO_id', 'doi', 'dimensions_id', 'title', 'abstract', 'authors', 'references', 'pub_date', 'affiliations_json', 'dimensions_cited']\n",
    "    df_articles = pd.DataFrame(columns=columns_extract)\n",
    "\n",
    "    for article in articles:\n",
    "        if 'doi' not in article:\n",
    "            continue\n",
    "        if article['doi'] in df_articles['doi']:\n",
    "            continue\n",
    "        df_article = pd.DataFrame(columns=columns_extract)\n",
    "        df_article['SO'] = [article['source_title']]\n",
    "        df_article['SO_id'] = [article['source_title_id']]\n",
    "        df_article['doi'] = [article['doi']]\n",
    "        df_article['dimensions_id'] = [article['id']]\n",
    "        df_article['title'] = [article['title']]\n",
    "        df_article['abstract'] = [article['abstract']]\n",
    "        if 'author_list' in article:\n",
    "            df_article['authors'] = [article['author_list']]\n",
    "        if 'cited_dimensions_ids' in article:\n",
    "            df_article['references'] = [len(article['cited_dimensions_ids'])]\n",
    "        if 'pub_date' in article:\n",
    "            df_article['pub_date'] = [article['pub_date']]\n",
    "        if 'affiliations_json' in article:\n",
    "            df_article['affiliations_json'] = [article['affiliations_json']]\n",
    "        df_article['dimensions_cited'] = [article['times_cited']]\n",
    "        df_articles = df_articles.append(df_article, ignore_index=True)\n",
    "\n",
    "    df_articles.to_csv(f'{origin_folder}/articles_wos_{journals_index}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_folder = origin_folder + '/articles_abs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for l in range(start_index, int(len(ori_journals) / sep_len)):\n",
    "    journals_index = str(1 + l * sep_len) + '-' + str((l + 1) * sep_len)\n",
    "    if journals_index == '801-900':\n",
    "        journals_index = '801-1100'\n",
    "    with open(f'{origin_folder}/articles_{journals_index}.json') as f:\n",
    "        articles = json.load(f)\n",
    "\n",
    "    columns_extract = ['SO', 'SO_id', 'doi', 'dimensions_id', 'title', 'abstract', 'authors', 'references', 'pub_date', 'affiliations_json', 'dimensions_cited']\n",
    "    df_articles = pd.DataFrame(columns=columns_extract)\n",
    "\n",
    "    for article in articles:\n",
    "        if 'doi' not in article:\n",
    "            continue\n",
    "        if article['doi'] in df_articles['doi']:\n",
    "            continue\n",
    "        df_article = pd.DataFrame(columns=columns_extract)\n",
    "        df_article['SO'] = [article['source_title']]\n",
    "        df_article['SO_id'] = [article['source_title_id']]\n",
    "        df_article['doi'] = [article['doi']]\n",
    "        df_article['dimensions_id'] = [article['id']]\n",
    "        df_article['title'] = [article['title']]\n",
    "        df_article['abstract'] = [article['abstract']]\n",
    "        if 'author_list' in article:\n",
    "            df_article['authors'] = [article['author_list']]\n",
    "        if 'cited_dimensions_ids' in article:\n",
    "            df_article['references'] = [len(article['cited_dimensions_ids'])]\n",
    "        if 'pub_date' in article:\n",
    "            df_article['pub_date'] = [article['pub_date']]\n",
    "        if 'affiliations_json' in article:\n",
    "            df_article['affiliations_json'] = [article['affiliations_json']]\n",
    "        df_article['dimensions_cited'] = [article['times_cited']]\n",
    "        df_articles = df_articles.append(df_article, ignore_index=True)\n",
    "\n",
    "    df_articles.to_csv(f'{origin_folder}/articles_{journals_index}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiliations Arrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pd.read_csv('SUSTC_Journals/articles_all/article_dimensions.csv', usecols=['doi', 'dimensions_id', 'affiliations_json'], nrows=600000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_researchers = pd.DataFrame()\n",
    "df_affiliations = pd.DataFrame()\n",
    "\n",
    "for index, item in df_articles.iterrows():\n",
    "    if index % 2000 == 0:\n",
    "        print(index)\n",
    "\n",
    "    doi = item['doi']\n",
    "    json_str = item['affiliations_json']\n",
    "    if pd.isna(json_str):\n",
    "        continue\n",
    "    for sub in json.loads(json_str):\n",
    "        df_researcherx = pd.DataFrame()\n",
    "        df_affiliationx = pd.DataFrame()\n",
    "\n",
    "        df_researcherx['doi'] = doi\n",
    "\n",
    "        if 'first_name' in sub:\n",
    "            df_researcherx['first_name'] = [sub['first_name']]\n",
    "        if 'last_name' in sub:\n",
    "            df_researcherx['last_name'] = [sub['last_name']]\n",
    "        if 'orcid' in sub:\n",
    "            df_researcherx['orcid'] = [sub['orcid']]\n",
    "        if 'current_organization_id' in sub:\n",
    "            df_researcherx['current_organization_id'] = [sub['current_organization_id']]\n",
    "        if 'researcher_id' in sub:\n",
    "            df_researcherx['researcher_id'] = [sub['researcher_id']]\n",
    "        if 'affiliations' in sub:\n",
    "            df_researcherx['affiliations_num'] = [len(sub['affiliations'])]\n",
    "        if 'raw_affiliation' in sub:\n",
    "            df_researcherx['raw_affiliation'] = [json.dumps(sub['raw_affiliation'])]\n",
    "\n",
    "        df_researchers = df_researchers.append(df_researcherx, ignore_index=True)\n",
    "\n",
    "        for subsub in sub['affiliations']:\n",
    "            if 'id' in subsub:\n",
    "                df_affiliationx['affiliation_id'] = [subsub['id']]\n",
    "            if 'name' in subsub:\n",
    "                df_affiliationx['name'] = [subsub['name']]\n",
    "            if 'city' in subsub:\n",
    "                df_affiliationx['city'] = [subsub['city']]\n",
    "            if 'city_id' in subsub:\n",
    "                df_affiliationx['city_id'] = [subsub['city_id']]\n",
    "            if 'country' in subsub:\n",
    "                df_affiliationx['country'] = [subsub['country']]\n",
    "            if 'country_code' in subsub:\n",
    "                df_affiliationx['country_code'] = [subsub['country_code']]\n",
    "            if 'state' in subsub:\n",
    "                df_affiliationx['state'] = [subsub['state']]\n",
    "            if 'state_code' in subsub:\n",
    "                df_affiliationx['state_code'] = [subsub['state_code']]\n",
    "\n",
    "            df_affiliations = df_affiliations.append(df_affiliationx, ignore_index=True)\n",
    "\n",
    "df_researchers.to_csv('SUSTC_Journals/articles_all/article_researchers_1.csv', index=False)\n",
    "df_affiliations.to_csv('SUSTC_Journals/articles_all/article_affiliations_1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondaa13ecd830a5e4b2c806b89eea66c1f7e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}