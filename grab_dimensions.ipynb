{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab Dimensions Data\n",
    "\n",
    "https://app.dimensions.ai/discover/publication\n",
    "\n",
    "This notebook handles the downloads of Dimensions data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search Params\n",
    "\n",
    "search_params logs what you want to search from Dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is very important for data fetching, generally you get url in the form as 'https://app.dimensions.ai/discover/publication?and_facet_for=2209&and_facet_for=2202&or_facet_source_title=jour.1082997', and search_params is just the substring after '?'.\n",
    "# Here is where we need to change for each search.\n",
    "search_params = 'and_facet_for=2209&and_facet_for=2202&or_facet_source_title=jour.1082997&or_facet_for=2421'"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Request Functions\n",
    "\n",
    "This part contains functions we need to fetch the web data and should also handle the exceptions while fetching here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from requests import ConnectionError, ReadTimeout\n",
    "\n",
    "def grab_from_url_content(url):\n",
    "    headers = {'Accept': '* / *',\n",
    "               'Accept-Language': 'zh-TW, zh; q=0.9, en-US; q=0.8, en; q=0.7, zh-CN; q=0.6',\n",
    "               'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3610.2 Safari/537.36'\n",
    "               }\n",
    "    rescontent = ''\n",
    "    try:\n",
    "        res = requests.get(url, headers=headers, timeout=10)\n",
    "        rescontent = res.text\n",
    "    except ConnectionError as ce:\n",
    "        print('ConnectionError: ' + str(ce))\n",
    "        return grab_from_url_content(url)\n",
    "    except ReadTimeout as rte:\n",
    "        print('ReadTimeout: ' + str(rte))\n",
    "        return grab_from_url_content(url)\n",
    "\n",
    "    return rescontent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parser\n",
    "\n",
    "We will get the html content from the url which is not listed as we want it be, so we need parser to parse them into listed data, in json form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class DimensionsHTMLParser(HTMLParser):\n",
    "    articles = []\n",
    "    in_article = False\n",
    "    is_next_trigger = False\n",
    "    next_trigger_url = ''\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == 'article':\n",
    "            self.in_article = True\n",
    "        \n",
    "        if self.in_article:\n",
    "            for attr in attrs:\n",
    "                if attr[0] == 'data-doc':\n",
    "                    self.articles.append(json.loads(attr[1]))\n",
    "                    break\n",
    "\n",
    "        if tag == 'a':\n",
    "            for attr in attrs:\n",
    "                if (attr[0] == 'class') and (attr[1] == 'nextPage-trigger'):\n",
    "                    self.is_next_trigger = True\n",
    "                if self.is_next_trigger and (attr[0] == 'href'):\n",
    "                    self.next_trigger_url = f'https://app.dimensions.ai{attr[1]}&{search_params}'\n",
    "                    break\n",
    "        return\n",
    "                    \n",
    "    def handle_endtag(self, tag):\n",
    "        if tag == 'article':\n",
    "            self.in_article = False\n",
    "        self.is_next_trigger = False\n",
    "        return\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        pass\n",
    "\n",
    "    def handle_comment(self, data):\n",
    "        pass\n",
    "\n",
    "    def handle_entityref(self, name):\n",
    "        pass\n",
    "\n",
    "    def handle_charref(self, name):\n",
    "        pass\n",
    "\n",
    "    def handle_decl(self, data):\n",
    "        pass\n",
    "\n",
    "parser = DimensionsHTMLParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grab Data\n",
    "\n",
    "The data fetching starts from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_url = f'https://app.dimensions.ai/discover/publication?{search_params}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n"
    }
   ],
   "source": [
    "%%time\n",
    "parser.feed(grab_from_url_content(grab_url))\n",
    "next_trigger_anchor = ''\n",
    "i = 0\n",
    "while parser.next_trigger_url != next_trigger_anchor:\n",
    "    if i % 10 == 0:\n",
    "        print(str(i))\n",
    "    i+=1\n",
    "    next_trigger_anchor = parser.next_trigger_url\n",
    "    parser.feed(grab_from_url_content(parser.next_trigger_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "129\nCPU times: user 149 Âµs, sys: 288 Âµs, total: 437 Âµs\nWall time: 294 Âµs\n"
    }
   ],
   "source": [
    "%%time\n",
    "print(len(parser.articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Journals/article_test.json\", \"w\") as dump_f:\n",
    "        dump_f.write(json.dumps(parser.articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}